---
title: "6: Robots"
desc: Going through the hardware
slides: true
---

## Robots are made up from many Subsystems

* Subsystems are 'represented' in the software
* Actuation (e.g. wheels)
* Sensing (e.g. cameras)
* Computing (e.g. brains)

:slide_title Concepts in Actuation

* 2 Wheel scenario
  * Differential drive: Turtlebot3
  * Turning by different speed on two or more wheels
  * Sometimes there is a caster
  * Can only move forward and backward.
* 4 Wheel Scenario
  * Not up and down or (directly) sideways
  * With more than 2 wheels, or a track - skid steering
  * Cars have "Ackerman" steering (4 wheels, 2 that can steer)
* Tracked Vehicles
  * Skid steering
* Holonomic - non-Holonomic
  * Holonomic - can move in any direction
* Manipulator Arms
  * Degrees of freedom
  * Coordinate transforms
  * Forward and reverse Kinematics
* Quadruped
  * Gait - trot, gallop, etc
  * Sensing vs. Non Sensing issues



## Case: Differential drive

:slide_title Lower Level

* Subscribes to `cmd_vel`
  * Desired translation and rotation speeds
  * Reverse kinematics tells us desired rotations per second for each wheel
* Publishes to `odom`
  * Forward kinematics tells us estimated actual motion (position and speed)
  * 'Dead Reckoning'

:slide_title Supporting hardware

* Two wheels + 1 or 2 casters
* Each wheel has motor and encoder
* Motor will go "faster" when given more current
* Encoder counts up for each rotation

:slide_title Algorithm
* PID control to minimize delta between desired and actual

## Sensors

:slide_title LiDAR
* Rotates and uses a laser to measure distance to nearest obstacle
* Returns a vector of values corresponding to the directions
* LiDAR's can operate in 2d (scan) or 3d (point cloud), ours is 2d

:callout :small, "Limitation", " Operates in a plane, like a disk. Can't detect an obstacle above or below the plane!"

:slide_title Visual Cameras

* Webcam sees a color picture
* Matrix of dots, each dot has a color
* `Dot[x,y] = {r,g,b}`
* Data can be processed for example with `opencv`
* A lot of data and a lot of processing
* Bandwidth limits



:slide_title Depth Cameras

* Like a Microsoft Kinect
* In addition to `{r,g,b}` also has distance so we get `{r,g,b,d}`
* Useful for getting range measurements of an object detected through camera



## Computation

* Distributed environment, typically:
  1. roscore running onboard. on Raspberry pi
  1. Some additional ROS nodes running on Raspberry Pi
  1. More ROS nodes running on a laptop or other computer
* Workload is truly distributed across all of those
* Eventually we may have to have a much beefier computer running all three
* This would make the robot much more independent

:slide_title Our actual Robots
1. Differential Drive - 2 powered wheels and one (or two) casters
1. Arduino or Arduino-like computer to control the motor.
1. Motor Controller and IMU directly connected to Arduino
1. Raspberry Pi which runs Ubuntu and ROS, connected to Arduino via a USB cable
1. Lidar connected to Raspberry Pi connected via USB cable
