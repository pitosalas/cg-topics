---
title: "PA: Fiducial Follow"
desc: "Robot follows a path laid out by fiducials"
---
## Introduction

This assignment will teach you a new method of localization using fiducial tags. The general concept is to use fiducial tags (they look like QR codes) to determine the distance and orientation of a robot relative to the tag.

With that information you can do SLAM and find the location of the tag relative to the global map using odometry. This is useful for multiple applications and we will use fiducials to follow a path defined by the tags in increasing order

### Purpose

This assignment has several purposes. First, in general it will be very useful to practice writing another ROS application. You will also learn about Fiducials and how to use them in ROS. Finally, you will learn about TFs and how to use them to control your robot.

### Assignment 

Write a single node or multi-node program that allows your robot to drive to one fiducial, turn around and return to another fiducial. There are many ways to solve this with the fiducial information and it is up to you to figure out what approach you want to take. There are additional challenges if you want to try something more complicated.

### What I hope you will learn

* What a ROS tf (transform) is
* Learn the basics of how fiducials work
* How to use fiducials in ROS
* How to use transform information to influence robotic control
* How to deal with a more complicated use case with TFs

### Background

You will find many different variations on fiducials and fiducial recognition. First at the high level there are April tags and Aruco tags. I have used Aruco and so that's what I prefer. If you want to try some different options, that's ok too. In this writeup I will focus on Aruco tags. I find that this is a [good introductory explanation](http://wiki.ros.org/fiducials) but there are many others.

[Aruco Detect](http://wiki.ros.org/aruco_detect) - A key ROS package that uses the image from the camera and detects an Aruco fiducial. It publishes two topics, /aruco_vertex and /fiducial_transforms. Probably though you will use TFs. This package automatically publishes a TF between the marker and the camera. You can analyze this tranasfor to figure out the relative position and orientation of the marker to the camera. Be careful, the orientation of the each of the coordinate systems is confusing and illogical. I mean what does it consider to be X, Y and Z in the tf is different from what you would expect. The best way to go is to visualize the tf in rviz.

A cool extension that you may be interested in for your project is [Fiducial SLAM](http://wiki.ros.org/fiducial_slam/). This package uses fiducials to do SLAM. It is a bit more complicated to use but it is a very cool package. It creates a kind of map of the relative positions of multiple Fiducials so that they can then be used for localization.

You will need to pay attention to your launch files and getting the whole thing to work. On the robot you will need the camera to be on, which means running raspicam or using one of the camera related launch files. On VNC you will need to run aruco detect because it will create the tfs that you need. In addition you should also run Rviz so you can see what is going on. And finally you will need to run your own node that subscribes to the fiducial transforms and uses them to control your robot.

### Getting Started

I suggesst you first get the robot set up, run the camera and aruco detect and see that you can visualize the transforms in rviz. Move the robot around to see how the tfs change. Print out the tfs on the console to see the relative distance and orientation.

Then you can start writing your own node. You will need to subscribe to the fiducial transforms. Learn the functions that will allow you to get the distance between the camera and the fiducial and the relative orientation. This will be the key info you need for your purposes.

Make sure that all the needed nodes are launched: raspicam to turn the camera on and aruco_detect to look for fiducials. If it is working then you will see a tf created for each fiducial that the camera sees at any instance. It doesn't remember.

Notice that the tf created will be named for the fiducial's numer, e.g. 100. This is the ID of the fiducial. You can use this to keep track of which fiducial you are looking at. You can also use the ID to determine which fiducial you are looking for next. When you created the fiducials or printed on the label there is a second number, e.g. 7, which is the same for all of them. That is the "dictionary number" which is just a classification of the type of fiducial.

With all this information it should be a simple task to have the robot drive towards fiducial "n" and detect when it is withint 0.3 meters from it. Then the robot should turn around and drive towards fiducial "n+1". Once it gets there you are done, unless you want to tackle further challenges.

### Additional Challenges for additional credit (no need to do them all!)

* Robot starts without either fiducial in sight
* Robot visits each of more than 2 fiducials, and visits them in order, and never twice.
* Robot uses fiducials to localize and then drive to a certain coordinate away rom it. For example, say that you consider the first fiducial to be 0,0. Then drive to 2,2 relative to that coordiante system, even though there's not a second fiducial

### Deliverables

* Commented Python source code file named "FirstnameLastname_PA#"
* Video of your program running in gazebo or your lab at home

